{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Data Analyst Test\n",
    "\n",
    "En primer lugar, se han seguido los pasos del README para correr el docker y cargar la BBDD de postgres. A través de la consola, he consultado la BBDD y he visto que tenía 3 tablas con los nombres *message_store*, *message_store_seq_seq* y *migrations*.\n",
    "\n",
    "A continuación, conectamos con la base de datos e importamos a dataframes de pandas las 3 tablas que hay en la base de datos.\n",
    "\n",
    "Los primeros pasos serán para conocer los datos y de limpieza de los mismos.\n",
    "\n",
    "## 0. Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'psycopg2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0a3685134d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmessage_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from message_store'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmessage_store_seq_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from message_store_seq_seq'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmigrations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from migrations'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'psycopg2' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "message_store = pd.read_sql_query('select * from message_store',con=psycopg2.connect(host=\"localhost\",database=\"test\", user=\"test\", password=\"test\"))\n",
    "message_store_seq_seq = pd.read_sql_query('select * from message_store_seq_seq',con=psycopg2.connect(host=\"localhost\",database=\"test\", user=\"test\", password=\"test\"))\n",
    "migrations = pd.read_sql_query('select * from migrations',con=psycopg2.connect(host=\"localhost\",database=\"test\", user=\"test\", password=\"test\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi intención, a continuación, es investigar qué contienen las tablas para saber qué información me va a ser útil para resolver el ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_store_seq_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(migrations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las líneas superiores vemos que:\n",
    "\n",
    "* La única tabla con datos útiles es la tabla *message_store*.\n",
    "* La tabla message_store contiene muchos datos que, a priori, parecen que no aportan información al ejercico.\n",
    "\n",
    "Lo primero que me llama la atención es la columna *payload* que contiene un diccionario. Muestro una de las filas al azar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_store.payload[125250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente veo que en dicha columna parece estar gran parte de la información que necesito. Paso a copiar el dataframe a una variable que llamo **df** en el que empiezo a limpiar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = message_store.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente muchos de los datos contienen información del sistema, que no es útil para las cuestiones del ejercicio y que además están repetidas.\n",
    "\n",
    "Hago *value_counts* para asegurar que no contienen información útil y que puedo prescindir de dichas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.type.value_counts())\n",
    "print(df.recipient.value_counts())\n",
    "print(df.sender.value_counts())\n",
    "print(df.publishable.value_counts())\n",
    "print(df.published.value_counts())\n",
    "print(df.publish_retries.value_counts())\n",
    "print(df.publish_error.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino todas estas columnas y las columnas que no aportan información. Me quedo solo con *occurred_on* y *payload*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"occurred_on\", \"payload\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer más manejable la información, convierto el diccionario en columnas del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df['occurred_on'], df['payload'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a limpiar. Eliminamos id y comprobamos que hay información que no aporta nada al ejercicio y podemos eliminar. Comprobamos además que la columna *trackedAt* contiene la misma información que *lastRideAt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"client\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"driverTask\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trackedAt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lastRideAt\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente las columnas que a priori nos pueden ser útiles son las siguientes, que alfamecenamos en un dataframe limpio de trabajo que llamo **dfw**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw = df[[\"occurred_on\",\"battery\",\"latitude\",\"longitude\",\"trackedAt\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creo un par de dataframes auxiliares que contienen las filas con datos de día y datos de noche respectivamente.\n",
    "\n",
    "Para el ejercicio he considerado que la noche empieza a las 21 y acaba a las 7 (inclusives), si bien se podrían considerar otras franjas según la necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night = dfw[(dfw[\"occurred_on\"].dt.hour >= 21) | (dfw[\"occurred_on\"].dt.hour <= 7)]\n",
    "df_day = dfw[(dfw[\"occurred_on\"].dt.hour < 21) | (dfw[\"occurred_on\"].dt.hour > 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compruebo que la selección está bien realizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night[\"occurred_on\"].dt.hour.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What's the battery average of the e-vehicles during the night?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night.battery.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La batería media durante la noche, según el rango horario seleccionado, es de **50,13%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What's the battery average of the e-vehicles during the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.battery.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La batería media durante el día, según el rango horario seleccionado, es también de **50,13%**.\n",
    "\n",
    "## 3. If e-vehicles must be picked-up to charge their battery when the level is lower than 40, what's the time range when most e-vehicles need to be recharged?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por comodidad he creado un par de columnas nuevas en el df:\n",
    "\n",
    "* Una con la hora\n",
    "* Otra que llamo *need_charge* que valdrá 1 si necesita carga (la batería es menor que 40) y 0 si no necesita ser recogida (la carga es del 40% o superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw[\"hour\"] = dfw[\"occurred_on\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw[\"need_charge\"] = dfw.battery.apply(lambda x: 1 if x <40 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw.need_charge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, a través de un groupby agrupo por horas, cuento los patines que necesitan carga y los ordeno de mayor a menor según el número de patinetes.\n",
    "\n",
    "**Se observa que el rango que más patinetes necesitan de recarga es el de 11 a 12 del mediodía.**\n",
    "\n",
    "Sin embargo, si elegimos rangos más amplios, se pueden sacar las siguientes conclusiones:\n",
    "\n",
    "* La noche en general necesita de más carga que el día (de 0:00 a 5 especialmente).\n",
    "* En el rango horario de 8:00 a 11:00 hay un pico de necesidades de recarga (con un descenso a las 9:00).\n",
    "        \n",
    "El gráfico que se muestra a continuación no no es todo lo \"visual\" que se desearía, ya que las columnas tienen una altura muy similar. Pero con algo de atención, se observan fácilmente las conclusiones mencionadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw[dfw.need_charge == 1].groupby(\"hour\").need_charge.count().reset_index(name='count')\\\n",
    "                                                .sort_values(['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "need_battery = dfw[dfw.need_charge == 1].groupby(\"hour\").need_charge.count().reset_index(name='count')\\\n",
    "                                                .sort_values(['hour'], ascending=True)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "plt.bar(need_battery.hour.tolist(), need_battery[\"count\"].tolist())\n",
    "# plt.xticks(x, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If e-vehicles must be picked-up to charge their battery when the level is lower than 40, what's the geozone with greater density of e-vehicles to be charged?\n",
    "\n",
    "Para representar geográficamente los datos he decidido utilizar folium, una librería de python que usa de fondo leaflet.js, una librería de javascript para construir mapas interactivos.\n",
    "\n",
    "Lo primero que hago, es agrupar los datos por latitud y longitud contando cuántos vehículos hay en cada coordenada que tengan una batería menor al 40%.\n",
    "\n",
    "A continuación, para que la representación sea más visual, normalizo los datos de la columna *count*, restando la media y dividiendo el resultado por la desviación estándar.\n",
    "\n",
    "He hecho dos representaciones:\n",
    "\n",
    "* La primera de ellas he creado un rango de radios: A mayor número de vehículos que necesitan carga, mayor es el radio. Además, los 5 puntos que más carga requieren, los he puesto en rojo, para diferenciarlos de los demás que están en azul.\n",
    "\n",
    "* La segunda representación es un mapa de calor creado con el plugin heatmap de folium.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = dfw[dfw.need_charge == 1].groupby([\"latitude\", \"longitude\"]).need_charge.count()\\\n",
    "                                .reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates[\"count_aux\"] = coordinates[\"count\"].copy()\n",
    "\n",
    "coordinates[\"count\"] = coordinates[\"count\"].apply(lambda x: (x-coordinates[\"count\"].mean())/coordinates[\"count\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import statistics\n",
    "\n",
    "lat = list(coordinates.latitude)\n",
    "lon = list(coordinates.longitude)\n",
    "count = list(coordinates[\"count\"])\n",
    "\n",
    "map = folium.Map(location=[df_charge.latitude.mean(), df_charge.longitude.mean()], zoom_start=12)\n",
    "\n",
    "for e in range(len(lat)):\n",
    "    latitude = lat[e]\n",
    "    longitude = lon[e]\n",
    "    \n",
    "    if count[e] < 0.2:\n",
    "        radio = 150\n",
    "    elif count[e] <0.4:\n",
    "        radio = 200\n",
    "    elif count[e] < 0.6:\n",
    "        radio = 250\n",
    "    elif count[e] < 0.8:\n",
    "        radio = 300\n",
    "    else:\n",
    "        radio = 400\n",
    "    \n",
    "    if e in range(5):\n",
    "        folium.Circle([latitude, longitude],\n",
    "                        radius=radio,\n",
    "                        color = \"red\",\n",
    "                        fill_color= '#f03',\n",
    "                        fill=True\n",
    "                       ).add_to(map)\n",
    "    else:\n",
    "        folium.Circle([latitude, longitude],\n",
    "                        radius=radio,\n",
    "                        fill=True\n",
    "                       ).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "\n",
    "def generateBaseMap(default_location=[dfw.latitude.mean(), dfw.longitude.mean()], default_zoom_start=12):\n",
    "    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map\n",
    "\n",
    "base_map = generateBaseMap()\n",
    "HeatMap(data=coordinates[['latitude', 'longitude', 'count']].groupby(['latitude', 'longitude']).sum().reset_index().values.tolist(), radius=15, max_zoom=13).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could you display on a heat map the density of e-vehicles in a timeline? Basically, we should be able to see how the density varies on the map as we change the timestamp.\n",
    "\n",
    "En este punto me he encontrado un problema. Folium permite realizar esto con el plugin *HeatMapWithTime*, sin embargo, parece que no funciona muy bien. \n",
    "\n",
    "No he podido ponerlo en marcha, pero es que tampoco puedo ver [los ejemplos de su página web](https://nbviewer.jupyter.org/github/python-visualization/folium/blob/master/examples/HeatMapWithTime.ipynb).\n",
    "\n",
    "Investigando por internet he visto que da fallos si tienes activado adblocks. He probado en varios navegadores y en varios ordenadores y no he conseguido ni siquiera ver el ejemplo, así que finalmente decidí realizarlo de otra manera.\n",
    "\n",
    "El código que utilicé es el siguiente.\n",
    "\n",
    "Los datos deben estar en una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_time = dfw.groupby([\"occurred_on\", \"latitude\", \"longitude\"]).need_charge.count().reset_index(name='count')\\\n",
    "                                                .sort_values(['occurred_on'], ascending=True)\n",
    "\n",
    "coordinates_time[\"count_aux\"] = coordinates_time[\"count\"].copy()\n",
    "coordinates_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hour_list = []\n",
    "for hour in coordinates_time[\"occurred_on\"].dt.hour.sort_values().unique():\n",
    "    df_hour_list.append(coordinates_time.loc[coordinates_time[\"occurred_on\"].dt.hour == hour, ['latitude', 'longitude']].groupby(['latitude', 'longitude']).sum().reset_index().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "base_map2 = generateBaseMap(default_zoom_start=11)\n",
    "HeatMapWithTime(df_hour_list, radius=15, gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'}, auto_play=True, min_opacity=0.5, max_opacity=0.8, use_local_extrema=True).add_to(base_map2)\n",
    "base_map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ellos, he decidio realizar este ejercicio con leaflet. Para ello he creado un pequeño documento html que contiene el script de Javascript para mostrar el mapa en leaflet.\n",
    "\n",
    "Para realizarlo, utilizo el plugin de leaflet **Leaflet.TimeDimension**.\n",
    "\n",
    "Lo primero que necesito es una nested list que contenga en el primer elemento el timestamp (en ms, que es lo que requiere el plugin) y en el segundo, una lista con todas las coordenadas donde hay vehículos a esa hora. Además, también recojo los pesos, es decir, cuántos vehículos hay en cada coordenada a cada hora.\n",
    "\n",
    "En primer lugar creo una nested list **con todos los datos** que contengan: el timestamp en ms, latitud, longitud y el peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "coordinates_time.occurred_on = coordinates_time.occurred_on.apply(lambda x: x.timestamp()*1000)\n",
    "\n",
    "times = coordinates_time.values.tolist()\n",
    "times.sort(key = lambda x: x[0]) \n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la nested list que queremos en la variable *date*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "date_aux = []\n",
    "weight = []\n",
    "for time in times:\n",
    "    if not time[0] in date_aux:\n",
    "        date_aux.append(time[0])\n",
    "        date.append([time[0]])\n",
    "        date[len(date)-1].append([[time[1],time[2]]])\n",
    "    else:\n",
    "        date[len(date)-1][1].append([time[1],time[2]])\n",
    "    weight.append(time[3])\n",
    "\n",
    "# Convertimos weigth a entero\n",
    "weight = [int(i) for i in weight]\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, creamos el documento html.\n",
    "\n",
    "Se puede construir con el plugin TimeDimension un script que te dibuje el mapa de calor como hacía folium. Sin embargo, no he tenido el tiempo suficiente como para saber cómo.\n",
    "\n",
    "Por el momento, presento un mapa de calor por cuadrículas donde cada una de ellas es más opaco, si hay más concentración de vehículos, o menos, si la concentración es más baja.\n",
    "\n",
    "El máximo de vehículos a la misma hora y en el mismo lugar es de 7, que es cuando la cuadrícula es totalmente opaca. No obstante, no estaría mal una leyenda.\n",
    "\n",
    "Seguiré trabajando en ello (en la leyenda y el heatmap).\n",
    "\n",
    "El código de acontinuación, crea el archivo html. Si se corre la celda del notebook, se abré directamente la página en el navegador. También se puede descargar el repositorio y abrir el archivo *maps.html* que se encuentra en el directorio *html.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "html = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "        #mapid { height: 180px; }\n",
    "        </style>\n",
    "        <title>Leaflet Heatmap with time</title>        \n",
    "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/leaflet@1.5.1/dist/leaflet.css\" />\n",
    "        <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/leaflet-timedimension@1.1.1/dist/leaflet.timedimension.control.min.css\" />\n",
    "    <body>\n",
    "    <header>\n",
    "    \n",
    "    </header>\n",
    "    <div id=\"mapid\" style=\"width: 100%; height: 100%;\"></div>\n",
    "    <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/leaflet@1.5.1/dist/leaflet.js\"></script>\n",
    "    <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/iso8601-js-period@0.2.1/iso8601.min.js\"></script>\n",
    "    <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/leaflet-timedimension@1.1.1/dist/leaflet.timedimension.min.js\"></script>\n",
    "\n",
    "    <script>\n",
    "    \n",
    "    L.TimeDimension.Layer.GeoJson.GeometryCollection = L.TimeDimension.Layer.GeoJson.extend({\n",
    "\n",
    "    // Do not modify features. Just return the feature if it intersects\n",
    "    // the time interval    \n",
    "    _getFeatureBetweenDates: function(feature, minTime, maxTime) {\n",
    "        var featureStringTimes = this._getFeatureTimes(feature);\n",
    "        if (featureStringTimes.length == 0) {\n",
    "            return feature;\n",
    "        }\n",
    "        var featureTimes = [];\n",
    "        for (var i = 0, l = featureStringTimes.length; i < l; i++) {\n",
    "            var time = featureStringTimes[i]\n",
    "            if (typeof time == 'string' || time instanceof String) {\n",
    "                time = Date.parse(time.trim());\n",
    "            }\n",
    "            featureTimes.push(time);\n",
    "        }\n",
    "\n",
    "        if (featureTimes[0] > maxTime || featureTimes[l - 1] < minTime) {\n",
    "            return null;\n",
    "        }\n",
    "        return feature;\n",
    "    },\n",
    "\n",
    "});\n",
    "\n",
    "L.timeDimension.layer.geoJson.geometryCollection = function(layer, options) {\n",
    "    return new L.TimeDimension.Layer.GeoJson.GeometryCollection(layer, options);\n",
    "};\n",
    "\n",
    "    var map = L.map('mapid', {\n",
    "    timeDimension: true,\n",
    "    timeDimensionOptions: {\n",
    "        timeInterval: \"2019-11-18/2019-12-25\",\n",
    "        period: \"PT1H\"\n",
    "    },\n",
    "    timeDimensionControl: true,\n",
    "    timeDimensionControlOptions:{\n",
    "        timeSteps: 24\n",
    "    }\n",
    "}).setView([\"\"\" + str(df_charge.latitude.mean()) + \"\"\", \"\"\" + str(df_charge.longitude.mean()) + \"\"\"], 13);\n",
    "\n",
    "\n",
    "function getCommonBaseLayers(map){\n",
    "    L.tileLayer('http://{s}.tile.osm.org/{z}/{x}/{y}.png').addTo(map);\n",
    "\n",
    "}\n",
    "\n",
    "// Create and add a TimeDimension Layer to the map\n",
    "var geoJsonFeatures = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"crs\": {\n",
    "    \"type\": \"name\",\n",
    "    \"properties\": {\n",
    "    \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\"\n",
    "    },\n",
    "  },\n",
    "  \"features\": [ \"\"\"\n",
    "\n",
    "contador = 1\n",
    "for timestamp in date:\n",
    "    html += \"\"\"{\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "          \"time\": \"\"\" + str(timestamp[0]) + \"\"\",\n",
    "          \"id\": \"\"\" + str(contador) + \"\"\",\n",
    "          \"opacity\":  \"\"\" + str(1 if weight[contador-1] == 7 else \\\n",
    "                                0.92 if weight[contador-1] == 6 else \\\n",
    "                                0.84 if weight[contador-1] == 5 else \\\n",
    "                                0.76 if weight[contador-1] == 4 else \\\n",
    "                                0.68 if weight[contador-1] == 3 else \\\n",
    "                                0.6 if weight[contador-1] == 2 else \\\n",
    "                                0.5 ) + \"\"\"\n",
    "        },\n",
    "        \"geometry\": {\n",
    "          \"type\": \"GeometryCollection\",\n",
    "          \"geometries\": [ \"\"\"\n",
    "    \n",
    "    for coord in timestamp[1]:\n",
    "        html += \"\"\"{\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [[\n",
    "        [\"\"\" + str(coord[1]-0.005) + \"\"\", \"\"\" + str(coord[0]-0.005) + \"\"\"],\n",
    "        [\"\"\" + str(coord[1]+0.005) + \"\"\", \"\"\" + str(coord[0]-0.005) + \"\"\"],\n",
    "        [\"\"\" + str(coord[1]+0.005) + \"\"\", \"\"\" + str(coord[0]+0.005) + \"\"\"],\n",
    "        [\"\"\" + str(coord[1]-0.005) + \"\"\", \"\"\" + str(coord[0]+0.005) + \"\"\"],\n",
    "        [\"\"\" + str(coord[1]-0.005) + \"\"\", \"\"\" + str(coord[0]-0.005) + \"\"\"]\n",
    "        ]]\n",
    "        },\"\"\"\n",
    "    \n",
    "    contador += 1\n",
    "    \n",
    "    html += \"\"\"]\n",
    "        }\n",
    "      },\"\"\"\n",
    "\n",
    "html += \"\"\"]\n",
    "};\n",
    "\n",
    "\n",
    "var geoJsonLayer = L.geoJson(geoJsonFeatures, {\n",
    "  style: function(feature) {    \n",
    "    return {\n",
    "      \"color\": \"#FF0000\",\n",
    "      \"opacity\": 0,\n",
    "      \"fillOpacity\": feature.properties.opacity\n",
    "    };\n",
    "  }\n",
    "});\n",
    "\n",
    "\n",
    "\n",
    "map.fitBounds(geoJsonLayer.getBounds());\n",
    "\n",
    "var geoJsonTimeLayer = L.timeDimension.layer.geoJson.geometryCollection(geoJsonLayer, {\n",
    "  updateTimeDimension: true,\n",
    "  updateTimeDimensionMode: 'replace',\n",
    "  duration: 'PT30M',\n",
    "});\n",
    "\n",
    "\n",
    "geoJsonTimeLayer.addTo(map);\n",
    "\n",
    "var baseLayers = getCommonBaseLayers(map);\n",
    "\n",
    "</script>\n",
    "\n",
    "    <footer>\n",
    "        <p>Alfonso Román Bonachera</p>\n",
    "    </footer>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "with open(\"html/maps.html\", \"w\") as file:\n",
    "    file.write(html)\n",
    "    \n",
    "webbrowser.open(\"html/maps.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
